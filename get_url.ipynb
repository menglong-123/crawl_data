{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 找个一个网站的根URL，然后爬取该网站下所有网页的URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from queue import Queue\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = {\n",
    "  'http': 'http://127.0.0.1:7890',\n",
    "  'https': 'http://127.0.0.1:7890',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.DEFAULT_RETRIES = 5\n",
    "s=requests.session()\n",
    "# 关闭多余连接\n",
    "s.keep_alive=False\n",
    "\n",
    "base_url = \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge(url): # 判断该URL是否应该保存， 自己根据网站的格式来写规则\n",
    "    return url.startswith(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue()\n",
    "q.put(base_url)\n",
    "res = set()\n",
    "res.add(base_url)\n",
    "bar = tqdm(total=10000)\n",
    "while not q.empty():\n",
    "    url = q.get()\n",
    "    try:\n",
    "        content = s.get(url, proxies=proxies)\n",
    "    except:\n",
    "        q.put(url)\n",
    "        time.sleep(1)\n",
    "        continue\n",
    "        \n",
    "    if content.ok:\n",
    "        soup = BeautifulSoup(content.text)\n",
    "        response = soup.select('a')\n",
    "        lists = []\n",
    "        for i in range(len(response)):\n",
    "            try:\n",
    "                lists.append(response[i]['href'])\n",
    "            except:\n",
    "                pass\n",
    "        lists = [i for i in lists if judge(i)]\n",
    "        # lists = [urljoin(base_url, i) for i in lists if judge(i)]\n",
    "        lists = list(set(lists))\n",
    "        for l in lists:\n",
    "            if l not in res:\n",
    "                res.add(l)\n",
    "                q.put(l)\n",
    "    else:\n",
    "        res.remove(url)\n",
    "    bar.set_description(\"len(set) = {}\".format(len(res)))\n",
    "    bar.update()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = list(res)\n",
    "fp = open(\"xxx.txt\", 'w', encoding='utf-8')\n",
    "for i in res:\n",
    "    fp.write(i + '\\n')\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
